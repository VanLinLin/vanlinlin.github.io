name: Update Google Scholar Data

on:
  workflow_dispatch:
  schedule:
    - cron: '0 8 * * *'

jobs:
  update-scholar:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v2

      - name: Set up Python 3
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r google_scholar_crawler/requirements.txt
          pip install scholarly

      - name: Run main.py to fetch Google Scholar stats
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          SERPAPI_API_KEY: ${{ secrets.SERPAPI_API_KEY }}
        run: |
          echo "üöÄ Starting scholar crawler"
          echo "import os" > run_scholar.py
          echo "import signal" >> run_scholar.py
          echo "import json" >> run_scholar.py
          echo "from scholarly import scholarly" >> run_scholar.py
          echo "os.environ['SCHOLARY_BACKEND'] = 'serpapi'" >> run_scholar.py
          echo "os.environ['SERPAPI_API_KEY'] = os.environ['SERPAPI_API_KEY']" >> run_scholar.py
          echo "def handler(signum, frame):" >> run_scholar.py
          echo "    raise TimeoutError('Timeout while fetching Google Scholar data')" >> run_scholar.py
          echo "signal.signal(signal.SIGALRM, handler)" >> run_scholar.py
          echo "signal.alarm(60)" >> run_scholar.py
          echo "print('üîç Fetching data for:', os.environ['GOOGLE_SCHOLAR_ID'])" >> run_scholar.py
          echo "author = scholarly.search_author_id(os.environ['GOOGLE_SCHOLAR_ID'])" >> run_scholar.py
          echo "author = scholarly.fill(author)" >> run_scholar.py
          echo "print('‚úÖ Done. Citations:', author['citedby'])" >> run_scholar.py
          echo "os.makedirs('google_scholar_crawler/results', exist_ok=True)" >> run_scholar.py
          echo "with open('google_scholar_crawler/results/gs_data.json', 'w') as f:" >> run_scholar.py
          echo "    json.dump(author, f, indent=2)" >> run_scholar.py
          echo "shieldsio_data = {'schemaVersion': 1, 'label': 'citations', 'message': str(author['citedby']), 'color': 'blue'}" >> run_scholar.py
          echo "with open('google_scholar_crawler/results/gs_data_shieldsio.json', 'w') as f:" >> run_scholar.py
          echo "    json.dump(shieldsio_data, f, indent=2)" >> run_scholar.py
          python run_scholar.py

      - name: Check output
        run: |
          ls -al google_scholar_crawler/results || echo "üìÇ Folder not found"
          cat google_scholar_crawler/results/gs_data.json || echo "‚ùå gs_data.json missing"
          cat google_scholar_crawler/results/gs_data_shieldsio.json || echo "‚ùå gs_data_shieldsio.json missing"

      - name: Commit and push updated JSON
        run: |
          cd google_scholar_crawler/results
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git init
          git remote add origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
          git checkout -b google-scholar-stats || git checkout google-scholar-stats
          git pull origin google-scholar-stats || echo "No previous branch"
          git add *.json
          git commit -m "üîÑ Update Google Scholar stats"
          git push origin google-scholar-stats --force
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
